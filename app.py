import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as transforms
import numpy as np
import cv2
import datetime as dt
import random as rd
from modulize.model import *
from modulize.crawl import *
# from etc.segmentation import *

# Load your model and set it to evaluation mode
model = torch.load("vitdetection2.pth", map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))
model.eval()

date = dt.datetime.today().strftime('%Y-%m-%d')
st.title("Emotion and Face Detection Web AppğŸ¤©")
st.write(f"ì•ˆë…•í•˜ì„¸ìš”ğŸ‘‹ğŸ» {date} ì˜¤ëŠ˜ì˜ ì…€ì¹´ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”ğŸ¥°")

uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
if uploaded_file is not None:
    image = Image.open(uploaded_file)
    width, height = image.size
    st.image(image, caption='Uploaded Image', use_column_width=True)
    st.write("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ê°ì •ì„ ë¶„ì„ì¤‘ì´ì—ìš”...ğŸ§")

    # Image transformations
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    image_np = np.array(image)
    image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    image_with_boxes = np.copy(image_np)

    # Convert BGR image to grayscale for face detection
    gray_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)
    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

    faces = face_classifier.detectMultiScale(
        gray_image, scaleFactor=1.1, minNeighbors=1, minSize=(40, 40)
    )

    if len(faces) > 0:
        x, y, w, h = faces[0]
    
    # Apply transformations
    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension

    # Move tensor to GPU if available
    if torch.cuda.is_available():
        image_tensor = image_tensor.to('cuda')

    # Make predictions
    predictions = model(image_tensor)
    emotion = torch.argmax(predictions[0], dim=1).cpu().item()
    # Prepare the image for drawing
    image_draw = np.array(image)
    image_draw = cv2.cvtColor(image_draw, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV

    # Correcting the start and end points
    #start_point = (int(bbox[2]*width/224), int(bbox[3]*height/224))
    #end_point = (int(bbox[0]*width/224),int(bbox[1]*height/224))


    color = (255, 0, 0)  # BGR format for a blue box
    thickness = 4
    if len(faces) > 0:
    # Find the largest face by area (w*h)
        largest_face = max(faces, key=lambda rect: rect[2] * rect[3])
        x, y, w, h = largest_face
        
        color = (255, 0, 0)  # BGR format for a blue box
        thickness = 2
        # Draw the rectangle around the largest detected face
        image_with_boxes = cv2.rectangle(image_with_boxes, (int(x), int(y)), (int(x+w), int(y+h)), color, thickness)

        # Convert back to RGB for displaying in Streamlit if necessary
        image_with_boxes = cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB)

        # Convert the NumPy array back to PIL Image for Streamlit
        final_image = Image.fromarray(image_with_boxes)
        st.image(final_image, caption='Uploaded Image with Detected Face', use_column_width=True)
      
    dict2 = {
        3:'ê¸°ì¨:heart_eyes:ì´',
        4:'ìƒì²˜:pensive:',
        0:'ë¶„ë…¸:rage:',
        2:'ë‹¹í™©:frowning:ì´',
        1:'ë¶ˆì•ˆ:worried:ì´',
        6:'ì¤‘ë¦½:neutral_face:ì´',
        5:'ìŠ¬í””:cry:ì´'
    }
    
    input_dict = {
        0: ['ê¸ì •ì ì¸ ìƒê°ìœ¼ë¡œ ë¶„ë…¸ë¥¼ ê°€ë¼ì•‰í˜€ë³´ì„¸ìš”ğŸ« ', 'ë¶„ë…¸ Stop!', 'ë‚´ì¼ì€ ì˜¤ëŠ˜ë³´ë‹¤ í›¨ì”¬ ë‚˜ì•„ì§ˆê±°ì˜ˆìš”~'],
        1: ['ë¶ˆì•ˆí•œ ê°ì •ì€ ê·¸ë§ŒğŸ–ğŸ» ë‹¤ ì˜ ë  ê±°ì˜ˆìš”!', 'ë¶ˆì•ˆí•¨ì€ ê²°êµ­ ë‚˜ë¥¼ ì„±ì¥ì‹œí‚¬ê±°ì˜ˆìš”!', 'ê·¸ë§Œ ë¶ˆì•ˆí•˜ê¸°~'],
        2: ['ë‹¹í™©ìŠ¤ëŸ½ê² ì§€ë§Œ ë¦´ë ‰ìŠ¤~', 'ì—¬ìœ ë¡œìš´ í‹°íƒ€ì„ ì–´ë– ì„¸ìš”?', 'ëª¨ë“ ì¼ì€ ë§ˆìŒë¨¹ê¸°ì— ë‹¬ë ¤ìˆì–´ìš”!'],
        3: ['ì–´ì œë³´ë‹¤ ê¸°ì¨ì´ âœŒğŸ»ë°°!!', 'ì˜¤ëŠ˜ë³´ë‹¤ ë‚´ì¼ ë” ê¸°ì ê±°ì˜ˆìš”ğŸŒ', 'ê¸°ì˜ë‹ˆê¹Œ ê¸°ì˜ë‹¤.'],
        4: ['ë…¸ë˜ë¡œ ìƒì²˜ë¥¼ ì¹˜ìœ í•´ë³´ì„¸ìš”ğŸ†', 'ìƒì²˜ëŠ” ê¸ˆë°© ê´œì°®ì•„ì§„ë‹¤~', 'ë³„ì¼ ì•„ë‹ˆì—ìš”. ê±±ì • ë§ˆì„¸ìš”!'],
        5: ['ìŠ¬í””ì€ ë‚˜ëˆ„ì–´ìš”!', 'ì™¸ë¡œì›Œë„ ìŠ¬í¼ë„ ë‚˜ëŠ” ì•ˆìš¸ì–´ğŸ¥²', 'ê¸ˆë°© ì‚¬ë¼ì§ˆ ìŠ¬í””...'],
        6: ['ì–¸ì œë‚˜ ì¤‘ê°„~', 'ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•Šì§€ë§Œ í•´í”¼í•´í”¼í•´í”¼~', 'ì˜¤ëŠ˜ ê¸°ë¶„ë„ ğŸ—ë„ ë°˜ë°˜!']
    }
    
    combined_entries = {**dict2, **input_dict}
    random_input = rd.choice(combined_entries[emotion])
    st.write(f"ì˜¤ëŠ˜ì˜ ê°ì •ì€ {dict2[emotion]}ë„¤ìš”! {random_input}")
    st.write(f"ë‹¹ì‹ ì˜ ì˜¤ëŠ˜ì˜ ê°ì •ì— ì•Œë§ëŠ” ë…¸ë˜ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!")
    # add 2 buttons ad if the button is clicked "ì˜ˆ", run if or "ì•„ë‹ˆì˜¤" else
    st.write("ë…¸ë˜ ëª©ë¡ì„ ì—…ë°ì´íŠ¸ í• ê¹Œìš”?")
    col1, col2 = st.columns(2)
    with col1:
        yes_button = st.button("ì˜ˆ")
    with col2:
        no_button = st.button("ì•„ë‹ˆì˜¤")

    # If "ì˜ˆ" is clicked
    if yes_button:
        # Placeholder for the code to execute when "ì˜ˆ" is clicked
        song_dataframe = crawl_analyze()
        # Example action: Show a message or perform some operation
        # You can replace this with your own logic or function call
        selected_song = random_song(emotion,song_dataframe)
        st.write("="*30)
        st.write(f"ì¶”ì²œ ë…¸ë˜ëŠ” \n {selected_song.iloc[0]['ê°€ìˆ˜']}ì˜ {selected_song.iloc[0]['ì œëª©']} ì…ë‹ˆë‹¤.")
        song_url = f"https://www.melon.com/song/detail.htm?songId={selected_song.iloc[0]['ID']}"
        link_html = f"<a href='{song_url}' target='_blank'><button style='margin: 10px; padding: 5px; border: none; color: white; background-color: #009688;'>ë…¸ë˜ ë“£ê¸°</button></a>"
        st.markdown(link_html, unsafe_allow_html=True)
        diary_entry = st.text_input("ì˜¤ëŠ˜ì˜ ê°„ë‹¨í•œ ì¼ê¸°ë¥¼ ì ì–´ì£¼ì„¸ìš”!")
        
    # If "ì•„ë‹ˆì˜¤" is clicked
    elif no_button:
        # Placeholder for the code to execute when "ì•„ë‹ˆì˜¤" is clicked
        # Example: Load a DataFrame and display or perform some operation
        song_dataframe = pd.read_csv("updated_dataset.csv")
        selected_song = random_song(emotion,song_dataframe)
        st.write(f"ì¶”ì²œ ë…¸ë˜ëŠ” {selected_song.iloc[0]['ê°€ìˆ˜']}ì˜ {selected_song.iloc[0]['ì œëª©']} ì…ë‹ˆë‹¤.")
        song_url = f"https://www.melon.com/song/detail.htm?songId={selected_song.iloc[0]['ID']}"
        link_html = f"<a href='{song_url}' target='_blank'><button style='margin: 10px; padding: 5px; border: none; color: white; background-color: #009688;'>ë…¸ë˜ ë“£ê¸°</button></a>"
        st.markdown(link_html, unsafe_allow_html=True)
        diary_entry = st.text_input("ì˜¤ëŠ˜ì˜ ê°„ë‹¨í•œ ì¼ê¸°ë¥¼ ì ì–´ì£¼ì„¸ìš”!")
        


    

    
        
